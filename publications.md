---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

**2025**

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/auxthink.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Aux-Think: Exploring Reasoning Strategies for Data-Efficient Vision-Language Navigation</strong><br/>
      Shuo Wang, Yongcai Wang, Wanting Li, Xudong Cai, Yucheng Wang, Maiyue Chen, Kaihui Wang, Zhizhong Su, Deying Li, <strong>Zhaoxin Fan</strong><br/>
      NeurIPS, 2025.<br/>
      [<a href="#">Paper</a>] [<a href="#">Code</a>]
    </p>
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/csur2025.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>A Comprehensive Taxonomy and Analysis of Talking Head Synthesis: Techniques for Portrait Generation, Driving Mechanisms, and Editing</strong><br/>
      Ming Meng, Yufei Zhao, Bo Zhang, Yonggui Zhu, Weimin Shi, Maxwell Wen, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM Computing Surveys (<strong>CSUR</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2406.10553">Paper</a>] [<a href="#">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/Jailbreak.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models</strong><br/>
      Xiayang Shi, Shangfeng Chen, Gang zhang,  <strong>Zhaoxin Fan</strong> (corresponding author), Yinlin Li, Wei Wei, Jingjing Liu<br/> 
      Pattern Recognition (<strong>PR</strong>), 2025.<br/> 
      [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325010520">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/asynfusion.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars</strong><br/>
      Tianbao Zhang, Jian Zhao, Yuer Li, Zheng Zhu, Ping Hu, <strong>Zhaoxin Fan</strong> (corresponding author), Wenjun Wu, Xuelong Li<br/> 
       Chinese Conference on Pattern Recognition and Computer Vision (<strong>PRCV</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2505.15058">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/longvla.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation</strong><br/>
     Yiguo Fan, Shuanghao Bai, Xinyang Tong, Pengxiang Ding, Yuyang Zhu, Hongchao Lu, Fengqi Dai, Wei Zhao, Yang Liu, Siteng Huang,   <strong>Zhaoxin Fan</strong> , Badong Chen, Donglin Wang<br/> 
      Conference on Robot Learning (<strong>CoRL</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2508.19958">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/cohedancers.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>CoheDancers: Enhancing Interactive Group Dance Generation through Music-Driven Coherence Decomposition</strong><br/>
      kaixing yang, XulongTang, Haoyu Wu, Biao Qin, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/> 
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2412.19123">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/flexible.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Flexible Multi-view Clustering with Dynamic Views Generation</strong><br/>
      Yalan Qin, Nan Pu, Hanzhou Wu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/> 
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/MSGM.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Moderating the Generalization of Score-based Generative Model</strong><br/>
      Wan Jiang, He Wang, Xin Zhang, Dan Guo,  <strong>Zhaoxin Fan</strong>, Yunfeng Diao, Richang Hong<br/> 
      International Conference on Computer Vision (<strong>ICCV</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2412.07229">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>



<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/carp.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction</strong><br/>
      Zhefei Gong, Pengxiang Ding, Shangke Lyu, Siteng Huang, Mingyang Sun, Wei Zhao,  <strong>Zhaoxin Fan</strong>, Donglin Wang<br/> 
      International Conference on Computer Vision (<strong>ICCV</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2412.06782">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/tba.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks</strong><br/>
      Zhiying Li, Yeying Jin, Fan Shen, Zhi Liu, Weibin Chen, Pengju Zhang, Xiaomei Zhang, Boyu Chen, Michael Shen, Kejian Wu, <strong>Zhaoxin Fan</strong> (corresponding author), Jin Dong<br/> 
      Pattern Recognition (<strong>PR</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2504.17457">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/phys.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Phys-EdiGAN: A privacy-preserving method for editing physiological signals in facial videos</strong><br/>
     Xiaoguang Tu, Zhiyi Niu, Juhang Yin, Yanyan Zhang, Ming Yang, Lin Wei, Yu Wang,  <strong>Zhaoxin Fan</strong>, Jian Zhao<br/> 
      Pattern Recognition (<strong>PR</strong>), 2025.<br/> 
      [<a href="https://www.sciencedirect.com/science/article/pii/S0031320325006260">Paper</a>] [<a href="https://github.com/">Code</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/saferag.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model</strong><br/>
      Xun Liang, Simin Niu, Zhiyu Li, Sensen Zhang, Hanyu Wang, Feiyu Xiong, <strong>Zhaoxin Fan</strong>, Bo Tang, Jihao Zhao, Jiawei Yang, Shichao Song, Mengwei Wang<br/>
      The 63rd Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2501.18636">Paper</a>] [<a href="https://github.com/IAAR-Shanghai/SafeRAG">Code</a>]
    </p>
  </div>
</div>



<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/moc.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System</strong><br/>
      Jihao Zhao, Zhiyuan Ji, <strong>Zhaoxin Fan</strong>, Hanyu Wang, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li<br/>
      The 63rd Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2503.09600">Paper</a>] [<a href="https://github.com/IAAR-Shanghai/Meta-Chunking/tree/main/MoC">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/eraseanything.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>EraseAnything: Enabling Concept Erasure in Rectified Flow Transformers</strong><br/>
      Daiheng Gao, Shilin Lu, Wenbo Zhou, Jiaming Chu, Jie Zhang, Mengxi Jia, Bang Zhang, <strong>Zhaoxin Fan</strong> (corresponding author), Weiming Zhang<br/>
      Forty-second International Conference on Machine Learning (<strong>ICML</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2412.20413">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/glditalker.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>GLDiTalker: Speech-Driven 3D Facial Animation with Graph Latent Diffusion Transformer</strong><br/>
      Yihong Lin, <strong>Zhaoxin Fan</strong> (Equal Contribution), Xianjia Wu, Lingyu Xiong, Liang Peng, Xiandong Li, Wenxiong Kang, Songju Lei, Huang Xu<br/>
      34th International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2408.01826">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/metaface1.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Meta-Learning Empowered Meta-Face: Personalized Speaking Style Adaptation for Audio-Driven 3D Talking Face Animation</strong><br/>
      Xukun Zhou, Fengxin Li, Ziqiao Peng, Xinyu Wang, Hongyan Liu, <strong>Zhaoxin Fan</strong> (corresponding author), Jun He<br/>
      IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2408.09357">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/twinpg.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Twin Progressive Generative Adversarial Network For High-Resolution Image Inpainting</strong><br/>
      Zhiying Li, Weibin Chen, <strong>Zhaoxin Fan</strong>, Kaichuan Kong, Xiaobo Jin, Guanggang Geng<br/>
      IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>), 2025.<br/>
      [<a href="https://arxiv.org/">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/dualtalk.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations</strong><br/>
      Ziqiao Peng, Yanbo Fan, Haoyu Wu, Xuan Wang, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2505.18096">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/mambavo.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MambaVO: Deep Visual Odometry Based on Sequential Matching Refinement Training Smoothing</strong><br/>
      Shuo Wang, Wanting Li, Yongcai Wang, <strong>Zhaoxin Fan</strong> (corresponding author), Zhe Huang, Xudong Cai, Jian Zhao, Deying Li<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2412.20082">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/jtd-uav.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems</strong><br/>
      Yifan Wang, Jian Zhao, <strong>Zhaoxin Fan</strong> (corresponding author), Xin Zhang, Xuecheng Wu, Yudian Zhang, Lei Jin, Xinyue Li, Gang Wang, Mengxi Jia, Ping Hu, Zheng Zhu, Xuelong Li<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025.<br/>
      [<a href="https://openaccess.thecvf.com/content/CVPR2025/html/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.html">Paper</a>] [<a href="https://github.com/wangyf2001/MM-AntiUAV/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/varges.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>VarGes: Improving Variation in Co-Speech 3D Gesture Generation via StyleCLIPS</strong><br/>
      Ming Meng, Ke Mu, Yonggui Zhu, Zhe Zhu, Haoyu Sun, Heyang Yan, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      Computational Visual Media (<strong>CVMJ</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2502.10729">Paper</a>] [<a href="https://github.com/mookerr/VarGES/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/idea2-3d.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Idea-2-3D: Collaborative LMM Agents Enable 3D Model Generation from Interleaved Multimodal Inputs</strong><br/>
      Junhao Chen, Xiang Li, Xiaojun Ye, <strong>Zhaoxin Fan</strong> (corresponding author), Hao Zhao<br/>
      The 31st International Conference on Computational Linguistics (<strong>COLING</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2404.04363">Paper</a>] [<a href="https://air-discover.github.io/Idea-2-3D/">Code</a>]
    </p>
  </div>
</div>

**2024**

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/mlphand.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MLPHand: Real Time Multi-View 3D Hand Mesh Reconstruction via MLP Modeling</strong><br/>
      Jian Yang, Jiakun Li, Guoming Li, Zhen Shen, Huai-Yu Wu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      European Conference on Computer Vision (<strong>ECCV</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2406.16137">Paper</a>] [<a href="https://github.com/jackyyang9/MLPHand">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/poserec.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Human Pose Driven Object Effects Recommendation</strong><br/>
      <strong>Zhaoxin Fan</strong>, Fengxin Li, Hongyan Liu, Jun He, and Xiaoyong Du<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2209.08353.pdf">Paper</a>] [<a href="https://github.com/FengxinLee/PoseRec">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/acrpose.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>ACR-Pose: Adversarial Canonical Representation Reconstruction Network for Category Level 6D Object Pose Estimation</strong><br/>
      <strong>Zhaoxin Fan</strong>, Zhenbo Song, Jian Xu, Zhicheng Wang, Kejian Wu, Hongyan Liu, and Jun He<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2111.10524.pdf">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/stdg.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>STDG: Semi-Teacher-Student Training Paradigram for Depth-guided One-stage Scene Graph Generation</strong><br/>
      Xukun Zhou, Zhenbo Song, Jun He, Hongyan Liu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2309.08179.pdf">Paper</a>] [<a href="https://github.com/zxk19981227/STDG">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/codancers.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>CoDancers: Music-Driven Coherent Group Dance Generation with Choreographic Unit</strong><br/>
      Kaixing Yang, Xukun Zhou, Xulong Tang, Ran Diao, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://dl.acm.org/doi/pdf/10.1145/3652583.3657998">Paper</a>] [<a href="https://github.com/XulongT/CoDancers">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/beatdance.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>BeatDance: A Beat-Based Model-Agnostic Contrastive Learning Framework for Music-Dance Retrieval</strong><br/>
      Kaixing Yang, Xukun Zhou, Xulong Tang, Ran Diao, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2310.10300.pdf">Paper</a>] [<a href="https://github.com/XulongT/BeatDance">Code</a>]
    </p>
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/synctalk.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis</strong><br/>
      Ziqiao Peng, Wentao Hu, Yue Shi, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Jun He, Hongyan Liu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2311.17590.pdf">Paper</a>] [<a href="https://github.com/ZiqiaoPeng/SyncTalk">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/monosim.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MonoSIM: Simulating Learning Behaviors of Heterogeneous Point Cloud Object Detectors for Monocular 3D Object Detection</strong><br/>
      Han Sun, <strong>Zhaoxin Fan</strong> (equal contribution), Zhenbo Song, Zhicheng Wang, Kejian Wu, and Jianfeng Lu<br/>
      IEEE Transactions on Instrumentation & Measurement (<strong>TIM</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2208.09446.pdf">Paper</a>] [<a href="https://github.com/sunh18/MonoSIM">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/everything2motion.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Everything2Motion: Synchronizing Diverse Inputs via a Unified Framework for Human Motion Synthesis</strong><br/>
      <strong>Zhaoxin Fan</strong>, Longbin Li, Pengxin Xu, Fan Shen, Kai Chen<br/>
      Thirty-Eighth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2024.<br/>
      [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/27936">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/furpe.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>FuRPE: Learning Full-body Reconstruction from Part Experts</strong><br/>
      <strong>Zhaoxin Fan</strong>, Yuqing Pan, Hao Xu, Zhenbo Song, Zhicheng Wang, Kejian Wu, Hongyan Liu, and Jun He<br/>
      Thirty-Eighth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>) Workshop, 2024.<br/>
      [<a href="https://arxiv.org/pdf/2212.00731.pdf">Paper</a>] [<a href="https://github.com/indigo-99/FuRPE">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/multidimensional-fusion.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Multi-dimensional Fusion and Consistency for Semi-supervised Medical Image Segmentation</strong><br/>
      Yixing Lu, <strong>Zhaoxin Fan</strong> (equal contribution), Min Xu<br/>
      International Conference on Multimedia Modeling (<strong>MMM</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2309.06618.pdf">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/transformer-autoencoder.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>A Novel Transformer Autoencoder for Multi-modal Emotion Recognition with Incomplete Data</strong><br/>
      Cheng Cheng, Wenzhe Liu, <strong>Zhaoxin Fan</strong>, Lin Feng, Ziyu Jia<br/>
      Neural Networks, 2024.<br/>
      [<a href="https://www.sciencedirect.com/science/article/pii/S089360802400025X?casa_token=adiVdzjLKUsAAAAA:2wBEqdxXN0qWvMjNQmyBENFLP1G6r4on2P63VmbOhkAfE4vUe0V56XgAjPyRQ7nE8drvaLN8-8Sp">Paper</a>]
    </p>
  </div>
</div>


**2023**

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/emotalk.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation</strong><br/>
      Ziqiao Peng, Haoyu Wu, Zhenbo Song, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      International Conference on Computer Vision (<strong>ICCV</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2303.11089.pdf">Paper</a>] [<a href="https://github.com/ZiqiaoPeng/EmoTalk">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/d-if.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>D-IF: Uncertainty-aware Human Digitization via Implicit Distribution Field</strong><br/>
      Xueting Yang, Yihao Luo, Yuliang Xiu, Wei Wang, Hao Xu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      International Conference on Computer Vision (<strong>ICCV</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2308.08857.pdf">Paper</a>] [<a href="https://github.com/psyai-net/D-IF_release">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/selftalk.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces</strong><br/>
      Ziqiao Peng, Yihao Luo, Yue Shi, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2306.10799.pdf">Paper</a>] [<a href="https://github.com/psyai-net/SelfTalk_release">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/deblurring.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Deep Semantic-aware Remote Sensing Image Deblurring</strong><br/>
      Zhenbo Song, Zhenyuan Zhang, Feiyi Fang, <strong>Zhaoxin Fan</strong>, Jianfeng Lu<br/>
      Signal Processing, 2023.<br/>
      [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0165168423001822">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/rapd.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Reconstruction-Aware Prior Distillation for Semi-supervised Point Cloud Completion</strong><br/>
      <strong>Zhaoxin Fan</strong>, Yulin He, Zhicheng Wang, Kejian Wu, Hongyan Liu, Jun He<br/>
      International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2204.09186.pdf">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/reflection.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Robust Single Image Reflection Removal Against Adversarial Attacks</strong><br/>
      Zhenbo Song, Zhenyuan Zhang, Kaihao Zhang, Wenhan Luo, <strong>Zhaoxin Fan</strong>, Wenqi Ren, Jianfeng Lu<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023.<br/>
      [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Robust_Single_Image_Reflection_Removal_Against_Adversarial_Attacks_CVPR_2023_paper.pdf">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/gidp.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>GIDP: Learning a Good Initialization and Inducing Descriptor Post-enhancing for Large-scale Place Recognition</strong><br/>
      <strong>Zhaoxin Fan</strong>, Zhenbo Song, Hongyan Liu, Jun He<br/>
      International Conference on Robotics and Automation (<strong>ICRA</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2209.11488.pdf">Paper</a>]
    </p>
  </div>
</div>


**2022**

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/old_net.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Object Level Depth Reconstruction for Category Level 6D Object Pose Estimation From Monocular RGB Image</strong><br/>
      Zhaoxin Fan, Zhenbo Song, Jian Xu, Zhicheng Wang, Kejian Wu, Hongyan Liu, Jun He<br/> 
      European Conference on Computer Vision (<strong>ECCV</strong>), 2022.<br/> 
      [<a href="https://arxiv.org/pdf/2204.01586.pdf">Paper</a>] [<a href="https://github.com/FANzhaoxin666/OLD_Net_release">Code</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/rpr_net.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>RPR-Net: A Point Cloud-based Rotation-Aware Large Scale Place Recognition Network</strong><br/>
      Zhaoxin Fan, Zhenbo Song, Wenping Zhang, Hongyan Liu, Jun He, Xiaoyong Du<br/> 
      European Conference on Computer Vision Workshop (<strong>ECCV Workshop</strong>), 2022.<br/> 
      [<a href="https://arxiv.org/pdf/2108.12790.pdf">Paper</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/svt_net.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>SVT-Net: Super Light-Weight Sparse Voxel Transformer for Large Scale Place Recognition</strong><br/>
      Zhaoxin Fan, Zhenbo Song, Zhiwu Lu, Hongyan Liu, Jun He, Xiaoyong Du<br/> 
      AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2022.<br/> 
      [<a href="https://arxiv.org/pdf/2105.00149.pdf">Paper</a>] [<a href="https://github.com/ZhenboSong/SVTNet">Code</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/icip.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Unsupervised Multi-task Learning for 3D Subtomogram Image Alignment, Clustering and Segmentation</strong><br/>
      Haoyi Zhu, Chuting Wang, Yuanxin Wang, Zhaoxin Fan, Mostofa Rafid Uddin, Xin Gao, Jing Zhang, Xiangrui Zeng, Min Xu<br/> 
      IEEE International Conference on Information Processing (<strong>ICIP</strong>), 2022.<br/> 
      [<a href="https://repository.kaust.edu.sa/server/api/core/bitstreams/97ddabc6-8dde-403c-a7f2-4da45368545f/content">Paper</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/pilotattnnet.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>PilotAttnNet: Multi-Modal Attention Network for End-to-End Steering Control</strong><br/>
      Jincan Zhang, Zhenbo Song, Jianfeng Lu, Xingwei Qu, Zhaoxin Fan<br/> 
      Chinese Conference on Pattern Recognition and Computer Vision (<strong>PRCV</strong>), 2022.<br/> 
      [<a href="https://link.springer.com/chapter/10.1007/978-3-031-18913-5_14">Paper</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/pose_tracking.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Deep Learning on Monocular Object Pose Detection and Tracking: A Comprehensive Overview</strong><br/>
      Zhaoxin Fan, Yazhi Zhu, Yulin He, Qi Sun, Hongyan Liu, Jun He<br/> 
      ACM Computing Surveys (<strong>CSUR</strong>), 2022.<br/> 
      [<a href="https://arxiv.org/pdf/2105.14291.pdf">Paper</a>] 
    </p> 
  </div>
</div>

**2020-2021**


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/srnet1.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>SRNet: A 3D Scene Recognition Network using Static Graph and Dense Semantic Fusion</strong><br/>
      Zhaoxin Fan, Hongyan Liu, Jun He, Qi Sun, Xiaoyong Du<br/> 
      Computer Graphics Forum (<strong>CGF</strong>), 2020.<br/> 
      [<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14146">Paper</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/graph_one_shot.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>A Graph‐based One‐Shot Learning Method for Point Cloud Recognition</strong><br/>
      Zhaoxin Fan, Hongyan Liu, Jun He, Qi Sun, Xiaoyong Du<br/> 
      Computer Graphics Forum (<strong>CGF</strong>), 2020.<br/> 
      [<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14147">Paper</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/mpdnet.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>MPDNet: A 3D Missing Part Detection Network Based on Point Cloud Segmentation</strong><br/>
      Zhaoxin Fan, Hongyan Liu, Jun He, Min Zhang, Xiaoyong Du<br/> 
      IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>), 2021.<br/> 
      [<a href="https://ieeexplore.ieee.org/abstract/document/9414867/">Paper</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/dagc.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>DAGC: Employing Dual Attention and Graph Convolution for Point Cloud based Place Recognition</strong><br/>
      Qi Sun, Hongyan Liu, Jun He, Zhaoxin Fan, Xiaoyong Du<br/> 
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2020.<br/> 
      [<a href="https://dl.acm.org/doi/abs/10.1145/3372278.3390693">Paper</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/pointfpn.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>PointFPN: A Frustum-based Feature Pyramid Network for 3D Object Detection</strong><br/>
      Zhaoxin Fan, Hongyan Liu, Jun He, Siwei Jiang, Xiaoyong Du<br/> 
      International Conference on Tools with Artificial Intelligence (<strong>ICTAI</strong>), 2020.<br/> 
      [<a href="https://ieeexplore.ieee.org/abstract/document/9288277">Paper</a>]
    </p> 
  </div>
</div>






**Patents**

*  Chinese National Invention Patent: 一种限高装置高度检测方法和系统. 国家发明专利. CN113658226A
*  Chinese National Invention Patent: 一种多视角图像的生成方法及装置. 国家发明专利. CN119625150A
*  Chinese National Invention Patent: 一种基于深度估计的单目物体三维重建方法及装置. CN119784930A
*  Chinese National Invention Patent: 基于视觉风格特征的多样性增强协同语音动作生成系统. 国家发明专利. CN119540034A
*  Chinese National Invention Patent: 基于动态神经网络和特征调制的零样本语音克隆方法. 国家发明专利. CN119360821A
*  Chinese National Invention Patent: 一种使用单目RGB图像进行虚拟人驱动的方法. 国家发明专利. CN116597509A
*  Chinese National Invention Patent:  一种基于 Wav2Lip 模型视频说话人的后处理方法. 国家发明专利. 2024113137542
*  Chinese National Invention Patent: 一种纹理重建方法及装置. 国家发明专利. 2024116956146
*  Chinese National Invention Patent:一种提高数字人姿态估计的对抗性攻击方法及装置. 国家发明专利. 202510427766.6
*  Chinese National Invention Patent:  基于双向对偶耦合的数字人表情编辑方法. 国家发明专利. 202510654473.1
*  Chinese National Invention Patent: 基于流形投影的数字人手-物协同视频生成方法. 国家发明专利. 202510654479.9



