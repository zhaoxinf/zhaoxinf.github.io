---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

**2026**
<!-- HVG-3D -->
<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/hvg3d.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>HVG-3D: Bridging Real and Simulation Domains for 3D-Conditional Hand-Object Interaction Video Synthesis</strong><br/>
      Mingjin Chen, Junhao Chen, <strong>Zhaoxin Fan</strong>(corresponding author), Yujian Lee, Zichen Dang, Yawen Cui, Lap-Pui Chau, Yi Wang, Lili Wang<br/>
      Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2026.<br/>
      [<a href="arxiv.org">Paper</a>]
      [<a href="github.com">Code</a>]
    </p>
  </div>
</div>

<!-- Progress-Think -->
<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/progressthink.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation</strong><br/>
      Shuo Wang, Yucheng Wang, Guoxin Lian, Yongcai Wang, Maiyue Chen, kaihui.wang, Bo Zhang, Zhizhong Su, Zhou Yutian, Wanting Li, Deying Li, <strong>Zhaoxin Fan</strong>(corresponding author)<br/>
      Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2026.<br/>
      [<a href="https://arxiv.org/pdf/2511.17097">Paper</a>]
      [<a href="https://horizonrobotics.github.io/robot_lab/progress-think/">Code</a>]
    </p>
  </div>
</div>

<!-- ActAvatar -->
<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/actavatar.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>ActAvatar: Temporally-Aware Precise Action Control for Talking Avatars</strong><br/>
      Ziqiao Peng, Yi Chen, Yifeng Ma, Guozhen Zhang, Zhiyao Sun, Zixiang Zhou, Youliang Zhang, Zhengguang Zhou, Zhaoxin Fan, Hongyan Liu, Yuan Zhou, Qinglin Lu, Jun He<br/>
      Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2026.<br/>
      [<a href="https://arxiv.org/pdf/2512.19546">Paper</a>]
      [<a href="https://ziqiaopeng.github.io/ActAvatar/">Code</a>]
    </p>
  </div>
</div>

<!-- CUBic -->
<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/cubic.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>CUBic: Coordinated Unified Bimanual Perception and Control Framework</strong><br/>
      Xingyu Wang, Pengxiang Ding, Jingkai Xu, Donglin Wang, <strong>Zhaoxin Fan</strong>(corresponding author)<br/>
      Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2026.<br/>
      [<a href="arxiv.org">Paper</a>]
      [<a href="github.com">Code</a>]
    </p>
  </div>
</div>

<!-- Lyapunov Probes -->
<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/lprobes.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Lyapunov Probes for Hallucination Detection in Large Foundation Models</strong><br/>
      Bozhi Luan, Gen Li, Yalan Qin, Jifeng Guo, Yun Zhou, Faguo Wu, Hongwei Zheng, <strong>Zhaoxin Fan</strong>(corresponding author), Wenjun Wu<br/>
      Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2026.<br/>
      [<a href="arxiv.org">Paper</a>]
      [<a href="github.com">Code</a>]
    </p>
  </div>
</div>

<!-- Erased, But Not Forgotten -->
<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/reflux.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Erased, But Not Forgotten: Erased Rectified Flow Transformers Still Remain Unsafe Under Concept Attack</strong><br/>
      Nanxiang Jiang,  <strong>Zhaoxin Fan</strong>(corresponding author), Enhan Kang, Daiheng Gao, Yun Zhou, Yanxia Chang, Zheng Zhu, Yeying Jin, Wenjun Wu<br/>
      Conference on Computer Vision and Pattern Recognition (<strong>CVPR (Findings)</strong>) , 2026.<br/>
      [<a href="https://arxiv.org/pdf/2510.00635">Paper</a>]
      [<a href="github.com">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/heelofllms.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>The Achilles' Heel of LLMs: How Altering a Handful of Neurons Can Cripple Language Abilities</strong><br/>
      Zixuan Qin, Kunlin Lyu, Qingchen Yu, <strong>Zhaoxin Fan</strong>(corresponding author), Yifan Sun<br/>
      International Conference on Learning Representations (<strong>ICLR</strong>), 2026.<br/>
      [<a href="https://arxiv.org/pdf/2510.10238">Paper</a>] 
      [<a href="https://github.com/qqqqqqqzx/The-Achilles-Heel-of-LLMs">Code</a>]
    </p>
  </div>  
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/robopara.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>RoboPARA: Dual-Arm Robot Planning with Parallel Allocation and Recomposition Across Tasks</strong><br/>
      Shiying Duan, Pei Ren, Nanxiang Jiang, Zhengping Che, Jian Tang, <strong>Zhaoxin Fan</strong>(corresponding author), Yifan Sun, Wenjun Wu<br/>
      International Conference on Learning Representations (<strong>ICLR</strong>), 2026.<br/>
      [<a href="https://arxiv.org/pdf/2506.06683">Paper</a>] 
      [<a href="https://github.com/AiDuanshiying/RoboPARA">Code</a>]
    </p>
  </div>  
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/poserft.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning</strong><br/>
      Bao Li, Xiaomei Zhang, Miao Xu, <strong>Zhaoxin Fan</strong>, Xiangyu Zhu, Zhen Lei<br/>
      International Conference on Learning Representations (<strong>ICLR</strong>), 2026.<br/>
      [<a href="https://arxiv.org/pdf/2508.07804" target="_blank">Paper</a>] 
      [<a href="https://github.com/" target="_blank">Code</a>]
    </p>
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
 <div class="column left" style="flex: 1;">
  <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/DSSmoothing.jpg">
</div>
<div class="column middle" style="flex: 0.05;">&nbsp;</div>
<div class="column right" style="flex: 2;">
  <p>
    <strong>DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing</strong><br/>
    Ting Qiao, Xing Liu, Wenke Huang, Jianbin Li, <strong>Zhaoxin Fan</strong>, Yiming Li<br/>
    The Web Conference (<strong>WWW</strong>), 2026.<br/>
    [<a href="https://arxiv.org/pdf/2510.15303" target="_blank">Paper</a>] [<a href="https://github.com/NcepuQiaoTing/DSSmoothing" target="_blank">Code</a>]
  </p>
 </div>
</div>

**2025**

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/eocd.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Entropy-optimized contrastive decoding for hallucination suppression in vision-language-action models</strong><br/>
      Ye Qiu, <strong>Zhaoxin Fan</strong> (corresponding author), Qingchen Yu, Faguo Wu, Hongwei Zheng, Yifan Sun, Wenjun Wu<br/>
      <em>Neurocomputing</em>, 2025.<br/>
      [<a href="https://www.sciencedirect.com/science/article/pii/S0925231225031790" target="_blank">Paper</a>] [<a href="https://github.com/" target="_blank">Code</a>]
    </p>
  </div>  
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/GRPCI.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>GRPCI: Harnessing Temporal-Spatial Dynamics for Graph Representation Learning</strong><br/>
      Xiang Wu, Rong-Hua Li, <strong>Zhaoxin Fan</strong>, Kai Chen, Yujin Gao, Hongchao Qin, and Guoren Wang<br/>
      IEEE Transactions on Knowledge and Data Engineering (<strong>TKDE</strong>), 2025.<br/>
      [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11271600">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>  
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/R-FGDepth.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>R-FGDepth: Towards Foundation Models for Recurrent Depth Learning with Frequency-Guided Initialization and Refinement</strong><br/>
      <strong>Zhaoxin Fan</strong>, Gen Li, Zhongkai Zhou<br/>
      Pattern Recognition (<strong>PR</strong>), 2025.<br/>
      [<a href="https://www.sciencedirect.com/science/article/pii/S0031320325015067">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>  
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/pruning.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>A Singular Learning Theory for Unified Large Language Model Pruning</strong><br/>
      Xinyu Wang, <strong>Zhaoxin Fan</strong> (corresponding author), Faguo Wu, Hongwei Zheng, Yuanze Hu, Gen Li, Zhichao Yang, Ye Qiu, Yifan Sun, Wenjun Wu<br/>
      <em>Neurocomputing</em>, 2025.<br/>
      [<a href="https://www.sciencedirect.com/science/article/abs/pii/S092523122502716X" target="_blank">Paper</a>] [<a href="https://github.com/" target="_blank">Code</a>]
    </p>
  </div>  
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/mem4d.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction</strong><br/>
      Xudong Cai, Shuo Wang, Peng Wang, Yongcai Wang, <strong>Zhaoxin Fan</strong> (corresponding author), Wanting Li, Tianbao Zhang, Jianrong Tao, Yeying Jin, Deying Li<br/>
      AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2026.<br/>
      [<a href="https://arxiv.org/pdf/2508.07908">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>  
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/monodream.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming</strong><br/>
      Shuo Wang, Yongcai Wang, Wanting Li, Yucheng Wang, Maiyue Chen, Kaihui Wang, Zhizhong Su, Xudong Cai, Yeying Jin, Deying Li, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2026.<br/>
      [<a href="https://arxiv.org/pdf/2508.02549">Paper</a>] [<a href="https://github.com/HorizonRobotics/RoboOrchardLab/tree/master/projects/monodream">Code</a>]
    </p>
  </div>  
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/synctalk++.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting</strong><br/>
      Ziqiao Peng, Wentao Hu, Junyuan Ma, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Hui Tian, Jun He, Hongyan Liu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/> 
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2506.14742">Paper</a>] [<a href="https://ziqiaopeng.github.io/synctalk++/">Code</a>]
    </p> 
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/auxthink.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Aux-Think: Exploring Reasoning Strategies for Data-Efficient Vision-Language Navigation</strong><br/>
      Shuo Wang, Yongcai Wang, Wanting Li, Xudong Cai, Yucheng Wang, Maiyue Chen, Kaihui Wang, Zhizhong Su, Deying Li,<strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      Neural Information Processing Systems Conference (<strong>NeurIPS</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2505.11886">Paper</a>]  [<a href="https://horizonrobotics.github.io/robot_lab/aux-think/">Code</a>]  
    </p>
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/csur2025.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>A Comprehensive Taxonomy and Analysis of Talking Head Synthesis: Techniques for Portrait Generation, Driving Mechanisms, and Editing</strong><br/>
      Ming Meng, Yufei Zhao, Bo Zhang, Yonggui Zhu, Weimin Shi, Maxwell Wen, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM Computing Surveys (<strong>CSUR</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2406.10553">Paper</a>] [<a href="#">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/Jailbreak.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Jailbreak Attack with Multimodal Virtual Scenario Hypnosis for Vision-Language Models</strong><br/>
      Xiayang Shi, Shangfeng Chen, Gang zhang,  <strong>Zhaoxin Fan</strong> (corresponding author), Yinlin Li, Wei Wei, Jingjing Liu<br/> 
      Pattern Recognition (<strong>PR</strong>), 2025.<br/> 
      [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325010520">Paper</a>] [<a href="#">Code</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/asynfusion.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars</strong><br/>
      Tianbao Zhang, Jian Zhao, Yuer Li, Zheng Zhu, Ping Hu, <strong>Zhaoxin Fan</strong> (corresponding author), Wenjun Wu, Xuelong Li<br/> 
       Chinese Conference on Pattern Recognition and Computer Vision (<strong>PRCV Best Student Paper& CCF outstanding Paper</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2505.15058">Paper</a>] [<a href="#">Code</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/longvla.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation</strong><br/>
     Yiguo Fan, Shuanghao Bai, Xinyang Tong, Pengxiang Ding, Yuyang Zhu, Hongchao Lu, Fengqi Dai, Wei Zhao, Yang Liu, Siteng Huang,   <strong>Zhaoxin Fan</strong> , Badong Chen, Donglin Wang<br/> 
      Conference on Robot Learning (<strong>CoRL</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2508.19958">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/cohedancers.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>CoheDancers: Enhancing Interactive Group Dance Generation through Music-Driven Coherence Decomposition</strong><br/>
      kaixing yang, XulongTang, Haoyu Wu, Biao Qin, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/> 
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2412.19123">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/flexible.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Flexible Multi-view Clustering with Dynamic Views Generation</strong><br/>
      Yalan Qin, Nan Pu, Hanzhou Wu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/> 
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2025.<br/> 
      [<a href="https://dl.acm.org/doi/10.1145/3746027.3754930">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/MSGM.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Moderating the Generalization of Score-based Generative Model</strong><br/>
      Wan Jiang, He Wang, Xin Zhang, Dan Guo,  <strong>Zhaoxin Fan</strong>, Yunfeng Diao, Richang Hong<br/> 
      International Conference on Computer Vision (<strong>ICCV</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2412.07229">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>



<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/carp.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction</strong><br/>
      Zhefei Gong, Pengxiang Ding, Shangke Lyu, Siteng Huang, Mingyang Sun, Wei Zhao,  <strong>Zhaoxin Fan</strong>, Donglin Wang<br/> 
      International Conference on Computer Vision (<strong>ICCV</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2412.06782">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/tba.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks</strong><br/>
      Zhiying Li, Yeying Jin, Fan Shen, Zhi Liu, Weibin Chen, Pengju Zhang, Xiaomei Zhang, Boyu Chen, Michael Shen, Kejian Wu, <strong>Zhaoxin Fan</strong> (corresponding author), Jin Dong<br/> 
      Pattern Recognition (<strong>PR</strong>), 2025.<br/> 
      [<a href="https://arxiv.org/pdf/2504.17457">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/phys.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Phys-EdiGAN: A privacy-preserving method for editing physiological signals in facial videos</strong><br/>
     Xiaoguang Tu, Zhiyi Niu, Juhang Yin, Yanyan Zhang, Ming Yang, Lin Wei, Yu Wang,  <strong>Zhaoxin Fan</strong>, Jian Zhao<br/> 
      Pattern Recognition (<strong>PR</strong>), 2025.<br/> 
      [<a href="https://www.sciencedirect.com/science/article/pii/S0031320325006260">Paper</a>] [<a href="https://github.com/">Code</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/saferag.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model</strong><br/>
      Xun Liang, Simin Niu, Zhiyu Li, Sensen Zhang, Hanyu Wang, Feiyu Xiong, <strong>Zhaoxin Fan</strong>, Bo Tang, Jihao Zhao, Jiawei Yang, Shichao Song, Mengwei Wang<br/>
      The 63rd Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2501.18636">Paper</a>] [<a href="https://github.com/IAAR-Shanghai/SafeRAG">Code</a>]
    </p>
  </div>
</div>



<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/moc.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System</strong><br/>
      Jihao Zhao, Zhiyuan Ji, <strong>Zhaoxin Fan</strong>, Hanyu Wang, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li<br/>
      The 63rd Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2503.09600">Paper</a>] [<a href="https://github.com/IAAR-Shanghai/Meta-Chunking/tree/main/MoC">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/eraseanything.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>EraseAnything: Enabling Concept Erasure in Rectified Flow Transformers</strong><br/>
      Daiheng Gao, Shilin Lu, Wenbo Zhou, Jiaming Chu, Jie Zhang, Mengxi Jia, Bang Zhang, <strong>Zhaoxin Fan</strong> (corresponding author), Weiming Zhang<br/>
      Forty-second International Conference on Machine Learning (<strong>ICML</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2412.20413">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/glditalker.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>GLDiTalker: Speech-Driven 3D Facial Animation with Graph Latent Diffusion Transformer</strong><br/>
      Yihong Lin, <strong>Zhaoxin Fan</strong> (Equal Contribution), Xianjia Wu, Lingyu Xiong, Liang Peng, Xiandong Li, Wenxiong Kang, Songju Lei, Huang Xu<br/>
      34th International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2408.01826">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/metaface1.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Meta-Learning Empowered Meta-Face: Personalized Speaking Style Adaptation for Audio-Driven 3D Talking Face Animation</strong><br/>
      Xukun Zhou, Fengxin Li, Ziqiao Peng, Xinyu Wang, Hongyan Liu, <strong>Zhaoxin Fan</strong> (corresponding author), Jun He<br/>
      IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2408.09357">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/twinpg.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Twin Progressive Generative Adversarial Network For High-Resolution Image Inpainting</strong><br/>
      Zhiying Li, Weibin Chen, <strong>Zhaoxin Fan</strong>, Kaichuan Kong, Xiaobo Jin, Guanggang Geng<br/>
      IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>), 2025.<br/>
      [<a href="https://arxiv.org/">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/dualtalk.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations</strong><br/>
      Ziqiao Peng, Yanbo Fan, Haoyu Wu, Xuan Wang, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2505.18096">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/mambavo.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MambaVO: Deep Visual Odometry Based on Sequential Matching Refinement Training Smoothing</strong><br/>
      Shuo Wang, Wanting Li, Yongcai Wang, <strong>Zhaoxin Fan</strong> (corresponding author), Zhe Huang, Xudong Cai, Jian Zhao, Deying Li<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2412.20082">Paper</a>] [<a href="https://github.com/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/jtd-uav.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems</strong><br/>
      Yifan Wang, Jian Zhao, <strong>Zhaoxin Fan</strong> (corresponding author), Xin Zhang, Xuecheng Wu, Yudian Zhang, Lei Jin, Xinyue Li, Gang Wang, Mengxi Jia, Ping Hu, Zheng Zhu, Xuelong Li<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025.<br/>
      [<a href="https://openaccess.thecvf.com/content/CVPR2025/html/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.html">Paper</a>] [<a href="https://github.com/wangyf2001/MM-AntiUAV/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/varges.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>VarGes: Improving Variation in Co-Speech 3D Gesture Generation via StyleCLIPS</strong><br/>
      Ming Meng, Ke Mu, Yonggui Zhu, Zhe Zhu, Haoyu Sun, Heyang Yan, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      Computational Visual Media (<strong>CVMJ</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2502.10729">Paper</a>] [<a href="https://github.com/mookerr/VarGES/">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/idea2-3d.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Idea-2-3D: Collaborative LMM Agents Enable 3D Model Generation from Interleaved Multimodal Inputs</strong><br/>
      Junhao Chen, Xiang Li, Xiaojun Ye, <strong>Zhaoxin Fan</strong> (corresponding author), Hao Zhao<br/>
      The 31st International Conference on Computational Linguistics (<strong>COLING</strong>), 2025.<br/>
      [<a href="https://arxiv.org/pdf/2404.04363">Paper</a>] [<a href="https://air-discover.github.io/Idea-2-3D/">Code</a>]
    </p>
  </div>
</div>

**2024**

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/mlphand.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MLPHand: Real Time Multi-View 3D Hand Mesh Reconstruction via MLP Modeling</strong><br/>
      Jian Yang, Jiakun Li, Guoming Li, Zhen Shen, Huai-Yu Wu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      European Conference on Computer Vision (<strong>ECCV</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2406.16137">Paper</a>] [<a href="https://github.com/jackyyang9/MLPHand">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/poserec.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Human Pose Driven Object Effects Recommendation</strong><br/>
      <strong>Zhaoxin Fan</strong>, Fengxin Li, Hongyan Liu, Jun He, and Xiaoyong Du<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2209.08353.pdf">Paper</a>] [<a href="https://github.com/FengxinLee/PoseRec">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/acrpose.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>ACR-Pose: Adversarial Canonical Representation Reconstruction Network for Category Level 6D Object Pose Estimation</strong><br/>
      <strong>Zhaoxin Fan</strong>, Zhenbo Song, Jian Xu, Zhicheng Wang, Kejian Wu, Hongyan Liu, and Jun He<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2111.10524.pdf">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/stdg.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>STDG: Semi-Teacher-Student Training Paradigram for Depth-guided One-stage Scene Graph Generation</strong><br/>
      Xukun Zhou, Zhenbo Song, Jun He, Hongyan Liu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2309.08179.pdf">Paper</a>] [<a href="https://github.com/zxk19981227/STDG">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/codancers.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>CoDancers: Music-Driven Coherent Group Dance Generation with Choreographic Unit</strong><br/>
      Kaixing Yang, Xukun Zhou, Xulong Tang, Ran Diao, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://dl.acm.org/doi/pdf/10.1145/3652583.3657998">Paper</a>] [<a href="https://github.com/XulongT/CoDancers">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/beatdance.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>BeatDance: A Beat-Based Model-Agnostic Contrastive Learning Framework for Music-Dance Retrieval</strong><br/>
      Kaixing Yang, Xukun Zhou, Xulong Tang, Ran Diao, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2310.10300.pdf">Paper</a>] [<a href="https://github.com/XulongT/BeatDance">Code</a>]
    </p>
  </div>
</div>


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/synctalk.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis</strong><br/>
      Ziqiao Peng, Wentao Hu, Yue Shi, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Jun He, Hongyan Liu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2311.17590.pdf">Paper</a>] [<a href="https://github.com/ZiqiaoPeng/SyncTalk">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/monosim.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>MonoSIM: Simulating Learning Behaviors of Heterogeneous Point Cloud Object Detectors for Monocular 3D Object Detection</strong><br/>
      Han Sun, <strong>Zhaoxin Fan</strong> (equal contribution), Zhenbo Song, Zhicheng Wang, Kejian Wu, and Jianfeng Lu<br/>
      IEEE Transactions on Instrumentation & Measurement (<strong>TIM</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2208.09446.pdf">Paper</a>] [<a href="https://github.com/sunh18/MonoSIM">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/everything2motion.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Everything2Motion: Synchronizing Diverse Inputs via a Unified Framework for Human Motion Synthesis</strong><br/>
      <strong>Zhaoxin Fan</strong>, Longbin Li, Pengxin Xu, Fan Shen, Kai Chen<br/>
      Thirty-Eighth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2024.<br/>
      [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/27936">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/furpe.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>FuRPE: Learning Full-body Reconstruction from Part Experts</strong><br/>
      <strong>Zhaoxin Fan</strong>, Yuqing Pan, Hao Xu, Zhenbo Song, Zhicheng Wang, Kejian Wu, Hongyan Liu, and Jun He<br/>
      Thirty-Eighth AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>) Workshop, 2024.<br/>
      [<a href="https://arxiv.org/pdf/2212.00731.pdf">Paper</a>] [<a href="https://github.com/indigo-99/FuRPE">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/multidimensional-fusion.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Multi-dimensional Fusion and Consistency for Semi-supervised Medical Image Segmentation</strong><br/>
      Yixing Lu, <strong>Zhaoxin Fan</strong> (equal contribution), Min Xu<br/>
      International Conference on Multimedia Modeling (<strong>MMM</strong>), 2024.<br/>
      [<a href="https://arxiv.org/pdf/2309.06618.pdf">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/transformer-autoencoder.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>A Novel Transformer Autoencoder for Multi-modal Emotion Recognition with Incomplete Data</strong><br/>
      Cheng Cheng, Wenzhe Liu, <strong>Zhaoxin Fan</strong>, Lin Feng, Ziyu Jia<br/>
      Neural Networks, 2024.<br/>
      [<a href="https://www.sciencedirect.com/science/article/pii/S089360802400025X?casa_token=adiVdzjLKUsAAAAA:2wBEqdxXN0qWvMjNQmyBENFLP1G6r4on2P63VmbOhkAfE4vUe0V56XgAjPyRQ7nE8drvaLN8-8Sp">Paper</a>]
    </p>
  </div>
</div>


**2023**

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/emotalk.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation</strong><br/>
      Ziqiao Peng, Haoyu Wu, Zhenbo Song, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      International Conference on Computer Vision (<strong>ICCV</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2303.11089.pdf">Paper</a>] [<a href="https://github.com/ZiqiaoPeng/EmoTalk">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/d-if.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>D-IF: Uncertainty-aware Human Digitization via Implicit Distribution Field</strong><br/>
      Xueting Yang, Yihao Luo, Yuliang Xiu, Wei Wang, Hao Xu, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      International Conference on Computer Vision (<strong>ICCV</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2308.08857.pdf">Paper</a>] [<a href="https://github.com/psyai-net/D-IF_release">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/selftalk.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces</strong><br/>
      Ziqiao Peng, Yihao Luo, Yue Shi, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, <strong>Zhaoxin Fan</strong> (corresponding author)<br/>
      ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2306.10799.pdf">Paper</a>] [<a href="https://github.com/psyai-net/SelfTalk_release">Code</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/deblurring.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Deep Semantic-aware Remote Sensing Image Deblurring</strong><br/>
      Zhenbo Song, Zhenyuan Zhang, Feiyi Fang, <strong>Zhaoxin Fan</strong>, Jianfeng Lu<br/>
      Signal Processing, 2023.<br/>
      [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0165168423001822">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/rapd.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Reconstruction-Aware Prior Distillation for Semi-supervised Point Cloud Completion</strong><br/>
      <strong>Zhaoxin Fan</strong>, Yulin He, Zhicheng Wang, Kejian Wu, Hongyan Liu, Jun He<br/>
      International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2204.09186.pdf">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/reflection.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>Robust Single Image Reflection Removal Against Adversarial Attacks</strong><br/>
      Zhenbo Song, Zhenyuan Zhang, Kaihao Zhang, Wenhan Luo, <strong>Zhaoxin Fan</strong>, Wenqi Ren, Jianfeng Lu<br/>
      IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023.<br/>
      [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Robust_Single_Image_Reflection_Removal_Against_Adversarial_Attacks_CVPR_2023_paper.pdf">Paper</a>]
    </p>
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;">
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/gidp.jpg">
  </div>
  <div class="column middle" style="flex: 0.05;">&nbsp;</div>
  <div class="column right" style="flex: 2;">
    <p>
      <strong>GIDP: Learning a Good Initialization and Inducing Descriptor Post-enhancing for Large-scale Place Recognition</strong><br/>
      <strong>Zhaoxin Fan</strong>, Zhenbo Song, Hongyan Liu, Jun He<br/>
      International Conference on Robotics and Automation (<strong>ICRA</strong>), 2023.<br/>
      [<a href="https://arxiv.org/pdf/2209.11488.pdf">Paper</a>]
    </p>
  </div>
</div>


**2022**

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/old_net.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Object Level Depth Reconstruction for Category Level 6D Object Pose Estimation From Monocular RGB Image</strong><br/>
      Zhaoxin Fan, Zhenbo Song, Jian Xu, Zhicheng Wang, Kejian Wu, Hongyan Liu, Jun He<br/> 
      European Conference on Computer Vision (<strong>ECCV</strong>), 2022.<br/> 
      [<a href="https://arxiv.org/pdf/2204.01586.pdf">Paper</a>] [<a href="https://github.com/FANzhaoxin666/OLD_Net_release">Code</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/rpr_net.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>RPR-Net: A Point Cloud-based Rotation-Aware Large Scale Place Recognition Network</strong><br/>
      Zhaoxin Fan, Zhenbo Song, Wenping Zhang, Hongyan Liu, Jun He, Xiaoyong Du<br/> 
      European Conference on Computer Vision Workshop (<strong>ECCV Workshop</strong>), 2022.<br/> 
      [<a href="https://arxiv.org/pdf/2108.12790.pdf">Paper</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/svt_net.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>SVT-Net: Super Light-Weight Sparse Voxel Transformer for Large Scale Place Recognition</strong><br/>
      Zhaoxin Fan, Zhenbo Song, Zhiwu Lu, Hongyan Liu, Jun He, Xiaoyong Du<br/> 
      AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2022.<br/> 
      [<a href="https://arxiv.org/pdf/2105.00149.pdf">Paper</a>] [<a href="https://github.com/ZhenboSong/SVTNet">Code</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/icip.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Unsupervised Multi-task Learning for 3D Subtomogram Image Alignment, Clustering and Segmentation</strong><br/>
      Haoyi Zhu, Chuting Wang, Yuanxin Wang, Zhaoxin Fan, Mostofa Rafid Uddin, Xin Gao, Jing Zhang, Xiangrui Zeng, Min Xu<br/> 
      IEEE International Conference on Information Processing (<strong>ICIP</strong>), 2022.<br/> 
      [<a href="https://repository.kaust.edu.sa/server/api/core/bitstreams/97ddabc6-8dde-403c-a7f2-4da45368545f/content">Paper</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/pilotattnnet.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>PilotAttnNet: Multi-Modal Attention Network for End-to-End Steering Control</strong><br/>
      Jincan Zhang, Zhenbo Song, Jianfeng Lu, Xingwei Qu, Zhaoxin Fan<br/> 
      Chinese Conference on Pattern Recognition and Computer Vision (<strong>PRCV</strong>), 2022.<br/> 
      [<a href="https://link.springer.com/chapter/10.1007/978-3-031-18913-5_14">Paper</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/pose_tracking.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>Deep Learning on Monocular Object Pose Detection and Tracking: A Comprehensive Overview</strong><br/>
      Zhaoxin Fan, Yazhi Zhu, Yulin He, Qi Sun, Hongyan Liu, Jun He<br/> 
      ACM Computing Surveys (<strong>CSUR</strong>), 2022.<br/> 
      [<a href="https://arxiv.org/pdf/2105.14291.pdf">Paper</a>] 
    </p> 
  </div>
</div>

**2020-2021**


<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/srnet_v2.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>SRNet: A 3D Scene Recognition Network using Static Graph and Dense Semantic Fusion</strong><br/>
      <strong>Zhaoxin Fan</strong>, Hongyan Liu, Jun He, Qi Sun, Xiaoyong Du<br/> 
      Computer Graphics Forum (<strong>CGF</strong>), 2020.<br/> 
      [<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14146">Paper</a>] 
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/graph_one_shot.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>A Graphbased OneShot Learning Method for Point Cloud Recognition</strong><br/>
      Zhaoxin Fan, Hongyan Liu, Jun He, Qi Sun, Xiaoyong Du<br/> 
      Computer Graphics Forum (<strong>CGF</strong>), 2020.<br/> 
      [<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14147">Paper</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/mpdnet.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>MPDNet: A 3D Missing Part Detection Network Based on Point Cloud Segmentation</strong><br/>
      Zhaoxin Fan, Hongyan Liu, Jun He, Min Zhang, Xiaoyong Du<br/> 
      IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>), 2021.<br/> 
      [<a href="https://ieeexplore.ieee.org/abstract/document/9414867/">Paper</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/dagc.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>DAGC: Employing Dual Attention and Graph Convolution for Point Cloud based Place Recognition</strong><br/>
      Qi Sun, Hongyan Liu, Jun He, Zhaoxin Fan, Xiaoyong Du<br/> 
      ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>), 2020.<br/> 
      [<a href="https://dl.acm.org/doi/abs/10.1145/3372278.3390693">Paper</a>]
    </p> 
  </div>
</div>

<div class="row" style="display: flex; align-items: center; margin-bottom: 20px;">
  <div class="column left" style="flex: 1;"> 
    <img align="left" width="100%" src="https://zhaoxinf.github.io/pic/pointfpn.jpg"> 
  </div> 
  <div class="column middle" style="flex: 0.05;">&nbsp;</div> 
  <div class="column right" style="flex: 2;"> 
    <p> 
      <strong>PointFPN: A Frustum-based Feature Pyramid Network for 3D Object Detection</strong><br/>
      Zhaoxin Fan, Hongyan Liu, Jun He, Siwei Jiang, Xiaoyong Du<br/> 
      International Conference on Tools with Artificial Intelligence (<strong>ICTAI</strong>), 2020.<br/> 
      [<a href="https://ieeexplore.ieee.org/abstract/document/9288277">Paper</a>]
    </p> 
  </div>
</div>






**Patents**

*  Chinese National Invention Patent: . . CN113658226A
*  Chinese National Invention Patent: . . CN119625150A
*  Chinese National Invention Patent: . CN119784930A
*  Chinese National Invention Patent: . . CN119540034A
*  Chinese National Invention Patent: . . CN119360821A
*  Chinese National Invention Patent: RGB. . CN116597509A
*  Chinese National Invention Patent:   Wav2Lip . . 2024113137542
*  Chinese National Invention Patent: . . 2024116956146
*  Chinese National Invention Patent:. . 202510427766.6
*  Chinese National Invention Patent:  . . 202510654473.1
*  Chinese National Invention Patent: -. . 202510654479.9



