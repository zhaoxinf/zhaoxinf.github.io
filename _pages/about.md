---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About me
======
* I am currently working as an assistant researcher, collaborating with Prof. [[Zhiming Zheng]](https://iai.buaa.edu.cn/info/1013/1088.htm), Academician of the Chinese Academy of Sciences and Prof. [[Wenjun Wu]](https://iai.buaa.edu.cn/info/1013/1093.htm), at School of Artificial Intelligence, Beihang University.  
  
* I am now also working as the chief young scientist of [Psyche AI Inc](https://www.psyai.com/home)（深锶科技）, fosuing on developing advanced AI algorithms for avatars, including avatar driving, avatar generation, and avatar reconsctrution. 

* I pursued my PhD from 2019 to 2024 across three prestigious institutions: [Carnegie Mellon University](https://www.cmu.edu)（卡内基梅隆大学）, [The Hong Kong University of Science and Technology](https://www.ust.hk)（香港科技大学）, and [Renmin University of China](https://www.ruc.edu.cn)（中国人民大学）, studying Computer Science (计算机科学). At CMU, I had the privilege of working under the guidance of Prof. [Min Xu](https://xulabs.github.io/min-xu/). My time at HKUST was spent collaborating with Prof. [Kai Chen](https://cse.hkust.edu.hk/~kaichen/). While at RUC, I worked closely with Prof. [Jun He](http://info.ruc.edu.cn/jsky/rtjs/index.htm) and Prof. [Hongyan Liu](https://www.sem.tsinghua.edu.cn/info/1210/32067.htm) from Tsinghua University. My research interests lie in the areas of multi-modal LLMs, avatars, and embodied AI.Please feel free to contact me by  email (fanzhaoxinruc@gmail.com or zhaoxinf@buaa.edu.cn), if you are interested in my research.



* If you are interested in becoming my student or a close collaborator, please answer the following questions before contacting me via email:
  * Firstly, familiarize yourself with my research area by reading my recent papers and visiting our research group's webpage. Research requires passion, and lack of interest may hinder persistence.
  * If you are applying for a direct PhD or a combined Master's and PhD program, it implies that you see academia as a career path. Please decide after understanding the challenges and rewards of an academic life.
  * When applying for a Master's program, I value excellent undergraduate grades, a solid foundation in mathematics, proficient programming skills, and good English proficiency.
  * I hope you are optimistic and proactive, with a resilient spirit, clear logical thinking, and good teamwork skills.
  * After considering these points, if you still wish to choose me as your mentor, please send your resume via email, including personal details, academic records, work or internship experiences, research experience, publications, and any other relevant information. I will respond as soon as possible.
 

* 范肇心博士现任北京航空航天大学人工智能学院郑志明院士团队助理研究员，兼北京航空航天大学国际创新研究院助理研究员、深锶科技首席青年科学家。博士期间分别就读于卡内基梅隆大学、香港科技大学和中国人民大学，研究方向包括 多模态大模型、数字人和具身智能。研究成果发表于 CVPR、ICCV、ECCV、AAAI、IJCAI 等国际顶级学术会议和期刊，累计发表近 40篇论文，主持和参与多项国家级及省市级科研项目，包括 国家自然科学基金重大项目、重点专项项目 和 北京市自然科学基金青年项目 等。在产业应用方面，范博士参与创立多家科技创新企业，累计融资超千万美元，技术成果已成功应用于 字节跳动、青岛CIM+智慧城市、中国电子科技集团 和 深锶科技 等多个项目。目前担任中国仿真学会算力系统仿真专业委员会执行委员 和 中国指挥与控制学会无人系统专业委员会委员。

* 现每年合作招收博士生2-3名、硕士生4-6名，并长期招收实习生。研究方向包括多模态大模型、数字人、具身智能及人工智能应用与产业化。博士、硕士招生地点为北京航空航天大学（学院路校区、杭州国际校区）及中国人民大学（北京校区）；实习生可选择线上或在北航杭州国际创新研究院工作。近期招收RA，base香港科技大学，优秀者可转PhD！




<br>

News!
======
*  March/30/2025,  We are hiring RAs at HKUST! Welcome to contact us by zhaoxinf@buaa.edu.cn!
*  March/21/2025,  Two paper are accepted to ICME 2025. Congrats to Xukun and Zhiying!
*  Feb/27/2025,  Excited to annouce that 3 papers are accepted to CVPR 2025 !
*  Feb/12/2025,  Excited to annouce that VarGes is  accepted to CVMJ. The impact factor of CVMJ is 17.3.
*  Dec/1/2024,  Glad to annouce that Idea-2-3d is accepted to Coling 2025 main track.
*  July/1/2024,  Glad to annouce that MLPHand is accepted to ECCV 2024 main track.
*  April/7/2024,  Excited to annouce that 5 papers are accepted to ICMR 2024.
*  March/22/2024,  Congrats to Han Sun for his first paper being accepted to IEEE Transactions on Instrumentation & Measurement.
*  Feb/27/2024,  Glad to annouce that SyncTalk is accepted to CVPR 2024 main track.
*  Dec/9/2023,  Our recent paper Everything2Motion is accepted to AAAI 2024 main track and the paper FurPE is accepted to AAAI 2024 workshop.  Congrats to all authors.
*  Nov/17/2023,  Congrats to Yixing Lu for his first paper being accepted to International Conference on Multimedia Modeling
*  Sep/21/2023,  We are awarded the second prize in the National Challenge Cup! I together with Professor [Li Ronghua](https://ronghuali.github.io/ronghuali.html) serve as the advisors of this project.
*  July/26/2023, I am thrilled to announce that our latest work, SelfTalk, has been accepted by ACM MM 2023!
*  Two papers D-IF and Emo-Talk are accepted by ICCV 2023, one of the best conference in computer vision.
*  Excited to annouce that one of our  papers has been accepted by signal processing, IF=4.729
*  Excited to annouce that one of my papers has been accepted by IJCAI 2023.
*  I am honored to have returned to Carnegie Mellon University as a visiting scholar.
*  One of my papers has been accepted for presentation at CVPR 2023, which is considered one of the most prestigious computer vision conferences in the world.
*  I am thrilled to have had one of my papers accepted for presentation at ICRA 2023, which is a leading robotics conference.
*  My research has been recognized at ECCV Workshop 2022, PRCV 2022, and ECCV 2022, all of which are highly-regarded international conferences in the field of computer vision.
*  I am proud to have had a paper accepted for publication in the ACM Computing Surveys journal, which is widely considered one of the best ACM journals with an impact factor of 14.324.
*  The virtual actor An-Ruohan of Psyai, which I helped to develop, performs her show daily on bilibili.
*  My research has also been recognized at ICIP 2022, which is a top-tier computer vision conference with a long-standing reputation for excellence.
*  I am excited to announce that one of my papers has been accepted for presentation at AAAI 2022, which is a leading artificial intelligence conference.



<br>


Working Experience
======
* Researcher, Psyche AI Inc (2021 - Present)
  * As a researcher at Psyche AI Inc, I am responsible for leading and overseeing various projects related to human body reconstruction, talking head technology, and 3D foundation models. In this role, I contribute my expertise in the development of innovative AI solutions that advance the field of computer vision and digital avatars.
    
    
* Remote Algorithm Researcher, Xreal (2021 - 2023)
  * As a Remote Algorithm Researcher at Xreal, my primary focus is on the research and development of algorithms for 6D object pose estimation, point cloud completion, and 3D foundation models. Working remotely, I collaborate with a team of researchers and engineers to design and implement cutting-edge algorithms that enhance the accuracy and efficiency of computer vision systems.
    
* Intern, Bytedance Inc (2020 - 2021)
  * During my internship at Bytedance Inc, I gained valuable experience in the field of computer vision, specifically in the areas of 6D object pose estimation, 3D object detection, and 3D object tracking. As an intern, I actively contributed to the development of algorithms and systems, working closely with experienced professionals in the industry.
 


<br>



Selected Publications
======

* **DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations** [[paper]](https://arxiv.org/) [[code]](https://github.com/)    
Ziqiao Peng, Yanbo Fan, Haoyu Wu, Xuan Wang, Hongyan Liu, Jun He, **Zhaoxin Fan(corresponding author)**     
IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2025


* **MambaVO: Deep Visual Odometry Based on Sequential Matching Refinement Training Smoothing** [[paper]](https://arxiv.org/pdf/2412.20082) [[code]](https://github.com/)    
Shuo Wang, Wanting Li, Yongcai Wang, **Zhaoxin Fan(corresponding author)**, Zhe Huang, Xudong Cai, Jian Zhao, Deying Li     
IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2025

* **JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems** [[paper]](https://arxiv.org/) [[code]](https://github.com/)    
Yifan Wang, Jian Zhao, **Zhaoxin Fan(corresponding author)**, Xin Zhang, Xuecheng Wu, Yudian Zhang, Lei Jin, Xinyue Li, Gang Wang, Mengxi Jia, Ping Hu, Zheng Zhu, Xuelong Li     
IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2025


* **MLPHand: Real Time Multi-View 3D Hand Mesh Reconstruction via MLP Modeling** [[paper]](https://arxiv.org/pdf/2406.16137) [[code]](https://github.com/jackyyang9/MLPHand)    
Jian Yang, Jiakun Li, Guoming Li, Zhen Shen, Huai-Yu Wu, **Zhaoxin Fan(corresponding author)**  
European Conference on Computer Vision, ECCV 2024

* **SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis** [[paper]](https://arxiv.org/pdf/2311.17590.pdf)[[code]](https://github.com/ZiqiaoPeng/SyncTalk)  
Ziqiao Peng, Wentao Hu, Yue Shi, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Jun He, Hongyan Liu, **Zhaoxin Fan (corresponding author)**.  
IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2024

* **MonoSIM: Simulating Learning Behaviors of Heterogeneous Point Cloud Object Detectors for Monocular 3D Object Detection** [[paper]](https://arxiv.org/pdf/2208.09446.pdf) [[code]](https://github.com/sunh18/MonoSIM)   
Han Sun, **Zhaoxin Fan (equal contribution)**, Zhenbo Song, Zhicheng Wang, Kejian Wu, and Jianfeng Lu.  
IEEE Transactions on Instrumentation & Measurement, TIM 2024

* **Everything2Motion: Synchronizing Diverse Inputs via a Unified Framework for Human Motion Synthesis**[[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/27936)    
**Zhaoxin Fan**, Longbin Li, Pengxin Xu, Fan Shen, kai Chen.  
Thirty-Eighth AAAI Conference on Artificial Intelligence, AAAI 2024

* **EmoTalk: Speech-driven emotional disentanglement for 3D face animation** [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.pdf) [[code]](https://github.com/psyai-net/EmoTalk_release)    
Ziqiao Peng, Haoyu Wu, Zhenbo Song, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, **Zhaoxin Fan(corresponding author)**.  
International Conference on Computer Vision, ICCV 2023

* **D-IF: Uncertainty-aware Human Digitization via Implicit Distribution Field** [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.pdf)[[code]](https://github.com/psyai-net/D-IF_release)   
Xueting Yang, Yihao Luo, Yuliang Xiu, Wei Wang, Hao Xu, **Zhaoxin Fan(corresponding author)**.  
International Conference on Computer Vision, ICCV 2023


* **SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces** [[paper]](https://arxiv.org/pdf/2306.10799.pdf)[[code]](https://github.com/psyai-net/SelfTalk_release)  
Ziqiao Peng, Yihao Luo, Yue Shi, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, **Zhaoxin Fan(corresponding author)**.  
ACM International Conference on Multimedia, ACM MM 2023


* **Reconstruction-Aware Prior Distillation for Semi-supervised Point Cloud Completion** [[paper]](https://arxiv.org/pdf/2204.09186.pdf)  
**Zhaoxin Fan**, Yulin He, Zhicheng Wang, Kejian Wu, Hongyan Liu and Jun He  
International Joint Conference on Artificial Intelligence, IJCAI 2023

* **Robust Single Image Reflection Removal Against Adversarial Attacks** [[paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Robust_Single_Image_Reflection_Removal_Against_Adversarial_Attacks_CVPR_2023_paper.pdf)    
Zhenbo Song, Zhenyuan Zhang, Kaihao Zhang, Wenhan Luo, **Zhaoxin Fan**, Wenqi Ren, Jianfeng Lu   
IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2023

* **Object Level Depth Reconstruction for Category Level 6D Object Pose Estimation From Monocular RGB Image** [[paper]](https://arxiv.org/pdf/2204.01586.pdf)[[code]](https://github.com/FANzhaoxin666/OLD_Net_release)       
**Zhaoxin Fan**, Zhenbo Song, Jian Xu, Zhicheng Wang, Kejian Wu, Hongyan Liu and Jun He  
European Conference on Computer Vision, ECCV 2022

* **SVT-Net: Super Light-Weight Sparse Voxel Transformer for Large Scale Place Recognition** [[paper]](https://arxiv.org/pdf/2105.00149.pdf)[[code]](https://github.com/ZhenboSong/SVTNet)    
**Zhaoxin Fan**, Zhenbo Song, Zhiwu Lu, Hongyan Liu, Jun He, and Xiaoyong Du  
36th AAAI Conference on Artificial Intelligence, AAAI 2022

* **Deep Learning on Monocular Object Pose Detection and Tracking: A Comprehensive Overview** [[paper]](https://arxiv.org/pdf/2105.14291.pdf)  
**Zhaoxin Fan**, Yazhi Zhu, Yulin He, Qi Sun, Hongyan Liu, and Jun He  
ACM Computing Surveys, CSUR, 2022.

* **GIDP: Learning a Good Initialization and Inducing Descriptor Post-enhancing for Large-scale Place Recognition** [[paper]](https://arxiv.org/pdf/2209.11488.pdf)    
**Zhaoxin Fan**, Zhenbo Song, Hongyan Liu, and Jun He  
International Conference on Robotics and Automation, ICRA 2023.

* **SRNet: A 3D Scene Recognition Network using Static Graph and Dense Semantic Fusion** [[paper]](https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14146)    
**Zhaoxin Fan**, Hongyan Liu, Jun He, Qi Sun, and Xiaoyong Du  
Computer Graphics Forum, CGF 2020  


* **A Graph‐based One‐Shot Learning Method for Point Cloud Recognition** [[paper]](https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14147)    
**Zhaoxin Fan**, Hongyan Liu, Jun He, Qi Sun, and Xiaoyong Du  
Computer Graphics Forum, CGF 2020 


<br>




